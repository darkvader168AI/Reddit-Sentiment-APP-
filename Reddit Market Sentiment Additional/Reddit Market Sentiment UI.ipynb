{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3130abb4",
   "metadata": {},
   "source": [
    "app.py\n",
    "analyzed_stock_data.csv   # from your existing pipeline\n",
    "requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09797bb",
   "metadata": {},
   "source": [
    "streamlit\n",
    "pandas\n",
    "numpy\n",
    "yfinance\n",
    "plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1901aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# ---------- Block A: Imports & Config ----------\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "# Safe in Streamlit runtime; harmless if imported elsewhere\n",
    "try:\n",
    "    st.set_page_config(page_title=\"Reddit Sentiment & Backtest\", layout=\"wide\")\n",
    "except Exception:\n",
    "    # Avoid notebook “ScriptRunContext” warning if accidentally executed here\n",
    "    pass\n",
    "\n",
    "DATA_FILE = \"analyzed_stock_data.csv\"   # must exist in the same folder\n",
    "BENCHMARK = \"SPY\"\n",
    "ENTRY = 0.05\n",
    "EXIT  = -0.05\n",
    "COST  = 0.001   # 0.1%\n",
    "TRADING_DAYS = 252\n",
    "DEFAULT_YEARS = 2  # backtest horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b0c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "# ---------- Block B: Data loaders ----------\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_reddit(filepath: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Date handling\n",
    "    if \"date_only\" in df.columns:\n",
    "        df[\"date_only\"] = pd.to_datetime(df[\"date_only\"])\n",
    "    elif \"created_utc\" in df.columns:\n",
    "        df[\"date_only\"] = pd.to_datetime(df[\"created_utc\"]).dt.normalize()\n",
    "    else:\n",
    "        raise ValueError(\"No date column found. Expected 'date_only' or 'created_utc'.\")\n",
    "\n",
    "    # Parse tickers list\n",
    "    def parse_tickers(x):\n",
    "        if isinstance(x, list): return x\n",
    "        if isinstance(x, str):\n",
    "            s = x.strip()\n",
    "            if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "                try: return ast.literal_eval(s)\n",
    "                except Exception: return []\n",
    "            return [t.strip().upper() for t in s.replace(\",\", \" \").split() if t.strip()]\n",
    "        return []\n",
    "    df[\"tickers\"] = df[\"tickers\"].apply(parse_tickers) if \"tickers\" in df.columns else [[]]*len(df)\n",
    "\n",
    "    if \"sentiment\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'sentiment' column in CSV.\")\n",
    "    if \"sentiment_label\" not in df.columns:\n",
    "        df[\"sentiment_label\"] = df[\"sentiment\"].apply(lambda s: \"Positive\" if s>0.05 else \"Negative\" if s<-0.05 else \"Neutral\")\n",
    "\n",
    "    for col in [\"title\", \"selftext\", \"url\", \"subreddit\", \"permalink\"]:\n",
    "        if col not in df.columns: df[col] = \"\"\n",
    "\n",
    "    # Make Streamlit cache happy\n",
    "    df[\"tickers\"] = df[\"tickers\"].apply(tuple)\n",
    "    return df\n",
    "\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def daily_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Average sentiment per (date, ticker).\"\"\"\n",
    "    e = df.explode(\"tickers\").dropna(subset=[\"tickers\"])\n",
    "    return (e.groupby([\"date_only\", \"tickers\"], as_index=False)[\"sentiment\"]\n",
    "              .mean()\n",
    "              .rename(columns={\"tickers\": \"ticker\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "114e0c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "# ---------- Block C: Price history ----------\n",
    "@st.cache_data(show_spinner=False)\n",
    "def get_price_history(tickers: list[str], start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:\n",
    "    df = yf.download(\n",
    "        tickers,\n",
    "        start=start.date(),\n",
    "        end=end.date(),\n",
    "        auto_adjust=True,   # adjusted Close → use \"Close\"\n",
    "        progress=False,\n",
    "        group_by=\"column\",\n",
    "        threads=True,\n",
    "    )\n",
    "\n",
    "    if isinstance(df, pd.Series):\n",
    "        df = df.to_frame()\n",
    "\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        if \"Close\" in set(df.columns.get_level_values(0)):\n",
    "            prices = df.xs(\"Close\", axis=1, level=0)\n",
    "        else:\n",
    "            prices = df.stack(0).groupby(level=[0,1]).last().unstack(1)\n",
    "    else:\n",
    "        if \"Close\" in df.columns and len(tickers) == 1:\n",
    "            prices = df[[\"Close\"]].rename(columns={\"Close\": tickers[0]})\n",
    "        else:\n",
    "            prices = df.copy()\n",
    "\n",
    "    if isinstance(prices, pd.Series):\n",
    "        prices = prices.to_frame()\n",
    "\n",
    "    prices.index.name = \"date_only\"\n",
    "    prices = prices.reindex(columns=[t for t in tickers if t in prices.columns])\n",
    "    return prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f22aacc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "# ---------- Block D: Strategy helpers & metrics ----------\n",
    "def build_daily_weights(signals_wide: pd.DataFrame) -> pd.DataFrame:\n",
    "    raw_long = (signals_wide > ENTRY).astype(int)\n",
    "    raw_exit = (signals_wide < EXIT).astype(int)\n",
    "    desired_pos = raw_long.shift(1).fillna(0).astype(int)\n",
    "    desired_pos = desired_pos.mask(raw_exit.shift(1) == 1, 0).fillna(0).astype(int)\n",
    "    weights = desired_pos.div(desired_pos.sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
    "    return weights\n",
    "\n",
    "def portfolio_returns(weights: pd.DataFrame, rets: pd.DataFrame, cost: float = COST) -> pd.Series:\n",
    "    gross = (weights * rets).sum(axis=1)\n",
    "    turnover = weights.diff().abs().sum(axis=1).fillna(0.0)\n",
    "    net = gross - cost * turnover\n",
    "    return net\n",
    "\n",
    "def perf_metrics(returns: pd.Series, benchmark_returns: pd.Series | None = None, trading_days: int = TRADING_DAYS):\n",
    "    r = returns.dropna()\n",
    "    if r.empty: return {}\n",
    "    equity = (1 + r).cumprod()\n",
    "    cum_return = equity.iloc[-1] - 1\n",
    "    ann_return = r.mean() * trading_days\n",
    "    ann_vol = r.std(ddof=0) * np.sqrt(trading_days)\n",
    "    sharpe = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "    dd = (equity / equity.cummax() - 1).min()\n",
    "    downside = r.where(r < 0, 0)\n",
    "    sortino = ann_return / (downside.std(ddof=0) * np.sqrt(trading_days) or np.nan)\n",
    "    out = {\n",
    "        \"Cumulative Return\": cum_return,\n",
    "        \"Annualized Return\": ann_return,\n",
    "        \"Annualized Volatility\": ann_vol,\n",
    "        \"Sharpe (rf=0)\": sharpe,\n",
    "        \"Sortino (rf=0)\": sortino,\n",
    "        \"Max Drawdown\": dd,\n",
    "    }\n",
    "    if benchmark_returns is not None and not benchmark_returns.dropna().empty:\n",
    "        te = (r - benchmark_returns.reindex_like(r)).std(ddof=0) * np.sqrt(trading_days)\n",
    "        info = ((ann_return - benchmark_returns.mean() * trading_days) / te) if te and te > 0 else np.nan\n",
    "        out[\"Information Ratio vs SPY\"] = info\n",
    "        out[\"Excess Ann Return vs SPY\"] = ann_return - benchmark_returns.mean() * trading_days\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d180dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "# ---------- Block E: UI ----------\n",
    "st.title(\"📈 Reddit Sentiment Dashboard & 2Y Strategy Backtest\")\n",
    "\n",
    "if not Path(DATA_FILE).exists():\n",
    "    st.error(f\"Could not find `{DATA_FILE}`. Put it next to app.py (or update DATA_FILE).\")\n",
    "    st.stop()\n",
    "\n",
    "data = load_reddit(DATA_FILE)\n",
    "signals = daily_signals(data)\n",
    "\n",
    "# Date range\n",
    "col1, col2 = st.columns(2)\n",
    "end_date = pd.Timestamp.today().normalize()\n",
    "start_date = end_date - pd.DateOffset(years=2)\n",
    "start_date = pd.Timestamp(col1.date_input(\"Start date\", start_date))\n",
    "end_date   = pd.Timestamp(col2.date_input(\"End date\",   end_date))\n",
    "\n",
    "available_tickers = sorted({t for ts in data[\"tickers\"] for t in ts})\n",
    "\n",
    "# --- Single ticker search\n",
    "st.subheader(\"🔎 Search a Ticker\")\n",
    "ticker_query = st.text_input(\"Type a ticker (e.g., NVDA, PLTR)\", value=(available_tickers[0] if available_tickers else \"\")).strip().upper()\n",
    "if ticker_query:\n",
    "    ex = data.explode(\"tickers\")\n",
    "    df_t = ex[(ex[\"tickers\"] == ticker_query) & (ex[\"date_only\"] >= start_date) & (ex[\"date_only\"] <= end_date)].copy()\n",
    "    total_posts = int(len(df_t))\n",
    "    avg_sent = float(df_t[\"sentiment\"].mean()) if total_posts > 0 else np.nan\n",
    "    dist = df_t[\"sentiment_label\"].value_counts(dropna=False).reindex([\"Positive\",\"Neutral\",\"Negative\"], fill_value=0)\n",
    "    c1,c2,c3 = st.columns(3)\n",
    "    c1.metric(\"Total posts\", f\"{total_posts:,}\")\n",
    "    c2.metric(\"Average sentiment\", \"N/A\" if np.isnan(avg_sent) else f\"{avg_sent:.3f}\")\n",
    "    c3.metric(\"Range\", f\"{start_date.date()} → {end_date.date()}\")\n",
    "    st.plotly_chart(px.bar(pd.DataFrame({\"Sentiment\":dist.index,\"Count\":dist.values}), x=\"Sentiment\", y=\"Count\", title=f\"Sentiment Distribution — {ticker_query}\"), use_container_width=True)\n",
    "    st.markdown(f\"### 🧵 Top Discussions mentioning **{ticker_query}**\")\n",
    "    sort_cols = [c for c in [\"score\",\"num_comments\"] if c in df_t.columns]\n",
    "    top_posts = (df_t.sort_values(by=sort_cols, ascending=False) if sort_cols else df_t).head(10)\n",
    "    if top_posts.empty:\n",
    "        st.info(\"No posts found in the selected range.\")\n",
    "    else:\n",
    "        for _, row in top_posts[[\"date_only\",\"title\",\"url\",\"subreddit\"]].fillna(\"\").iterrows():\n",
    "            d = pd.to_datetime(row[\"date_only\"]).date() if row[\"date_only\"] else \"\"\n",
    "            title = row[\"title\"] or \"(no title)\"\n",
    "            sub = row[\"subreddit\"]; url = row[\"url\"]\n",
    "            bullet = f\"- **{d}** — {title}\"\n",
    "            if sub: bullet += f\" _(r/{sub})_\"\n",
    "            if url: bullet += f\" — [link]({url})\"\n",
    "            st.markdown(bullet)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# --- Portfolio backtest\n",
    "st.subheader(\"🧺 Portfolio Backtest (2 Years) vs SPY\")\n",
    "tickers_input = st.text_input(\"Enter up to 5 tickers (comma-separated):\", value=\", \".join([t for t in [\"NVDA\",\"PLTR\"] if t in available_tickers]) if available_tickers else \"\")\n",
    "sel = [t.strip().upper() for t in tickers_input.split(\",\") if t.strip()]\n",
    "sel = [t for t in sel if t in available_tickers][:5]\n",
    "show_per_stock = st.checkbox(\"Show individual stock strategy curves vs SPY\", value=True)\n",
    "\n",
    "if sel:\n",
    "    sig_wide = (signals.pivot(index=\"date_only\", columns=\"ticker\", values=\"sentiment\")\n",
    "                      .reindex(pd.date_range(start_date, end_date, freq=\"B\"))\n",
    "                      .fillna(0.0))\n",
    "    sel = [t for t in sel if t in sig_wide.columns]\n",
    "    if sel:\n",
    "        sig_wide = sig_wide[sel]\n",
    "        prices = get_price_history(sel + [BENCHMARK], start=start_date, end=end_date).reindex(sig_wide.index).ffill().dropna(how=\"all\", axis=1)\n",
    "        if BENCHMARK not in prices.columns:\n",
    "            st.error(\"Could not fetch SPY from yfinance.\"); st.stop()\n",
    "        common = [t for t in sel if t in prices.columns]\n",
    "        if not common:\n",
    "            st.error(\"No overlap between selected tickers and available prices.\"); st.stop()\n",
    "        sel = common; sig_wide = sig_wide[sel]\n",
    "        rets = prices[sel].pct_change().fillna(0.0)\n",
    "        spy_rets = prices[BENCHMARK].pct_change().fillna(0.0)\n",
    "        w = build_daily_weights(sig_wide).reindex(columns=sel).fillna(0.0)\n",
    "        port_net = portfolio_returns(w, rets, cost=COST)\n",
    "        m = perf_metrics(port_net, spy_rets)\n",
    "        st.markdown(\"#### Performance (Net of 0.1% costs)\")\n",
    "        st.dataframe(pd.DataFrame({k:[v] for k,v in m.items()}, index=[\"Portfolio\"]).style.format(\"{:.4f}\"), use_container_width=True)\n",
    "        eq_df = pd.DataFrame({\"Portfolio (Net)\": (1+port_net).cumprod(), \"SPY\": (1+spy_rets).cumprod()}).dropna()\n",
    "        st.plotly_chart(px.line(eq_df, title=\"Equity Curve — Portfolio vs SPY\"), use_container_width=True)\n",
    "        roll = pd.DataFrame({\n",
    "            \"Portfolio 1Y Sharpe\": port_net.rolling(TRADING_DAYS).mean()/port_net.rolling(TRADING_DAYS).std(ddof=0),\n",
    "            \"SPY 1Y Sharpe\": spy_rets.rolling(TRADING_DAYS).mean()/spy_rets.rolling(TRADING_DAYS).std(ddof=0),\n",
    "        }).dropna()\n",
    "        if not roll.empty:\n",
    "            st.plotly_chart(px.line(roll, title=\"Rolling 1-Year Sharpe\"), use_container_width=True)\n",
    "        if show_per_stock:\n",
    "            st.markdown(\"#### Per-Stock Strategy (Net) vs SPY\")\n",
    "            for t in sel:\n",
    "                pos  = (sig_wide[t].shift(1) > ENTRY).astype(int)\n",
    "                exi  = (sig_wide[t].shift(1) < EXIT).astype(int)\n",
    "                pos  = pos.mask(exi==1, 0).fillna(0).astype(int)\n",
    "                to   = pos.diff().abs().fillna(0.0)\n",
    "                net  = pos * rets[t].fillna(0.0) - COST*to\n",
    "                df_t = pd.DataFrame({f\"{t} Strategy (Net)\": (1+net).cumprod(), \"SPY\": (1+spy_rets).cumprod()}).dropna()\n",
    "                st.plotly_chart(px.line(df_t, title=f\"Equity Curve — {t} vs SPY\"), use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"Selected tickers not present in your dataset's signals.\")\n",
    "else:\n",
    "    st.info(\"Enter up to 5 tickers to run the 2-year backtest vs SPY.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
